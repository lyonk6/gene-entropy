# gene-entropy

In information theory the Shannon entropy is given by:

$H(X) = -\sum_{i=1}^{n} P(x_i) log P(x_i)$

&emsp;&emsp;$n$ 
$-\sum P(x_i) log P(x_i) = H(x)$  
&ensp;$i=1$
